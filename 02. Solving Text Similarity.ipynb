{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving text similarity problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text similarity problem deals with the challenge of finding how close given text documents are.\n",
    "\n",
    "In this part we will take a look into how to solve similarity problem using TF-IDF (Term Frequency Inverse Document Frequency)\n",
    "\n",
    "Let's understand this by depicting into TF and IDF:\n",
    "- TF (Term Frequency): is a tehnique to find the frequency of a word in a given document\n",
    "Here, we normalize the frequency with respect to the total words that are present in the document and compute the TF value of a word\n",
    "\n",
    "- IDF (Inverse document frequency): is a tehnique in which we make sure that words that are frequently used (a, the, and so on) are given a lower weight when compared to words that are rarely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import nltk\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSimilarity:\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) - define constructor which takes sample sentences on which we want to find the similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.statements = [\n",
    "            \"The sky is blue and beautiful.\",\n",
    "            \"Love this blue and beautiful sky!\",\n",
    "            \"The quick brown fox jumps over the lazy dog.\",\n",
    "            \"A king’s breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "            \"I love green eggs, ham, sausages and bacon!\",\n",
    "            \"The brown fox is quick and the blue dog is lazy!\",\n",
    "            \"The sky is very blue and the sky is very beautiful today\",\n",
    "            \"The dog is lazy but the brown fox is quick!\",\n",
    "            \"President greets the press in Chicago\",\n",
    "            \"Obama speaks in Illinois\"\n",
    "        ]\n",
    "        \n",
    "    \"\"\" \n",
    "    (2) - define TF() method which takes as input a sentence.\n",
    "        - convert the sentce to lower case and extract all words\n",
    "        - find frequency distribution of these words using nltk FreqDist function\n",
    "        - iterate over all dictionary keys, build the normalized floating values and store them into a dictionary\n",
    "        - return dictionary that contains the normalized score for each word in the sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    def TF(self, sentence):\n",
    "        \"\"\"\n",
    "        Method to return a dictionary where key is the word and value its frequency.\n",
    "        \"\"\"\n",
    "        \n",
    "        # tokenize sentence and lower case each word\n",
    "        words = nltk.word_tokenize(sentence.lower())\n",
    "\n",
    "        # get frequency distribution\n",
    "        freq = nltk.FreqDist(words)\n",
    "        \n",
    "        # define an empty dictionary\n",
    "        dictionary = {}\n",
    "        \n",
    "        # iterate over all frequency distribution keys\n",
    "        for key in freq.keys():\n",
    "            # build TF for each word by normalizing floating values\n",
    "            norm = freq[key]/float(len(words))\n",
    "            dictionary[key] = norm\n",
    "        \n",
    "        return dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    (3) - define IDF() method that finds the IDF value for all the words in all documents.\n",
    "        - define a local function caled idf() representing the formula for finding IDF of a given word\n",
    "        - iterate over all the statements and convert them to lowercase\n",
    "        - find the number of occurences of each word that is present across all the documents\n",
    "        - build the IDF value for all words and return the dictionary containing these IDF values\n",
    "    \"\"\"\n",
    "    def IDF(self):\n",
    "        \"\"\"\n",
    "        Method to find and return the IDF for all the words in all documents.\n",
    "        \"\"\"\n",
    "        def idf(TotalNumberOfDocuments, NumberOfDocumentsWithThisWord):\n",
    "            \"\"\"\n",
    "            Local function to find the IDF of a given word.\n",
    "            \"\"\"\n",
    "            return 1.0 + math.log(TotalNumberOfDocuments/NumberOfDocumentsWithThisWord)\n",
    "        \n",
    "        numDocuments = len(self.statements)\n",
    "        uniqueWords = {}\n",
    "        idfValues = {}\n",
    "        \n",
    "        for sentence in self.statements:\n",
    "            for word in nltk.word_tokenize(sentence.lower()):\n",
    "                # find how many times each word is present across all documents\n",
    "                if word not in uniqueWords:\n",
    "                    uniqueWords[word] = 1\n",
    "                else:\n",
    "                    uniqueWords[word] += 1\n",
    "        \n",
    "        # build IDF value for all words\n",
    "        for word in uniqueWords:\n",
    "            idfValues[word] = idf(numDocuments, uniqueWords[word])\n",
    "        return idfValues\n",
    "    \n",
    "    \"\"\"\n",
    "    (4) - define a method to perform TF*IDF for all documents against a given search string.\n",
    "        - break the string into tokens\n",
    "        - build IDF() for all sentences in the self.statements variable\n",
    "        - iterate over all sentences and find the TF for all words in the sentence\n",
    "        - filter and use only the words that are present in the input search string \n",
    "        - build the vectors that consist of ff*idf values against each document\n",
    "        - return the list of vectors for each word in the search query\n",
    "    \"\"\"\n",
    "    def TF_IDF(self, query):\n",
    "        \"\"\"\n",
    "        Method to perform TF * IDF for all documents against a given search string \n",
    "        and return the list of vectors for each word in the search query.\n",
    "        \"\"\"\n",
    "        \n",
    "        # break the search string into tokens\n",
    "        words = nltk.word_tokenize(query.lower())\n",
    "        \n",
    "        # build IDF() for all sentences\n",
    "        idf = self.IDF()\n",
    "        \n",
    "        vectors = {}\n",
    "        # iterate over all sentences \n",
    "        for sentence in self.statements:\n",
    "            # find all TF for all words in the sentence\n",
    "            tf = self.TF(sentence)\n",
    "            # filter and use only the words that are present in the input search string\n",
    "            for word in words:\n",
    "                tf_vector = tf[word] if word in tf else 0.0\n",
    "                idf_vector = idf[word] if word in idf else 0.0\n",
    "                # build tf*idf\n",
    "                multiplication = tf_vector * idf_vector\n",
    "                if word not in vectors:\n",
    "                    vectors[word] = []\n",
    "                else:\n",
    "                    vectors[word].append(multiplication)\n",
    "        \n",
    "        return vectors\n",
    "    \n",
    "    \"\"\"\n",
    "    (5) - define function to display the contents of vectors on the screen\n",
    "    \"\"\"\n",
    "    def displayVectors(self, vectors):\n",
    "        print(self.statements)\n",
    "        for word in vectors:\n",
    "            print(\"{} -> {}\".format(word, vectors[word]))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    (6) - define function to compute cosine similarity score\n",
    "        - create a new vectorizer object\n",
    "        - build matrix of TF-IDF values for all the documents that we are interested in using fit_transform() function\n",
    "    \"\"\"\n",
    "    def cosineSimilarity(self):\n",
    "        vec = TfidfVectorizer()\n",
    "        matrix = vec.fit_transform(self.statements)\n",
    "        for j in range(1, 5):\n",
    "            i = j - 1\n",
    "            print(\"\\tsimilarity of document {} with others\".format(i))\n",
    "            similarity = cosine_similarity(matrix[i:j], matrix)\n",
    "            print(similarity)\n",
    "            \n",
    "    \"\"\"\n",
    "    (7) - define run function \n",
    "        - take the first statement as input query to compare with other sentences\n",
    "        - display TF*IDF vectors for all sentences on screen\n",
    "        - print consine similarity computed for all the sentences usign scikit library\n",
    "    \"\"\"      \n",
    "    def run(self):\n",
    "        inputQuery = self.statements[0]\n",
    "        vectors = self.TF_IDF(inputQuery)\n",
    "        self.displayVectors(vectors)\n",
    "        self.cosineSimilarity()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sky is blue and beautiful.', 'Love this blue and beautiful sky!', 'The quick brown fox jumps over the lazy dog.', 'A king’s breakfast has sausages, ham, bacon, eggs, toast and beans', 'I love green eggs, ham, sausages and bacon!', 'The brown fox is quick and the blue dog is lazy!', 'The sky is very blue and the sky is very beautiful today', 'The dog is lazy but the brown fox is quick!', 'President greets the press in Chicago', 'Obama speaks in Illinois']\n",
      "the -> [0.0, 0.2, 0.0, 0.0, 0.16666666666666666, 0.16666666666666666, 0.18181818181818182, 0.16666666666666666, 0.0]\n",
      "sky -> [0.273755818839165, 0.0, 0.0, 0.0, 0.0, 0.3193817886456925, 0.0, 0.0, 0.0]\n",
      "is -> [0.0, 0.0, 0.0, 0.0, 0.2261124906564554, 0.2261124906564554, 0.2466681716252241, 0.0, 0.0]\n",
      "blue -> [0.273755818839165, 0.0, 0.0, 0.0, 0.15969089432284625, 0.15969089432284625, 0.0, 0.0, 0.0]\n",
      "and -> [0.2158322319665701, 0.0, 0.08887209551564651, 0.13734778397872643, 0.12590213531383254, 0.12590213531383254, 0.0, 0.0, 0.0]\n",
      "beautiful -> [0.314853257760848, 0.0, 0.0, 0.0, 0.0, 0.18366440036049464, 0.0, 0.0, 0.0]\n",
      ". -> [0.0, 0.26094379124341005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\tsimilarity of document 0 with others\n",
      "[[1.         0.60757112 0.14815826 0.06301636 0.08140207 0.53825587\n",
      "  0.71064091 0.35137022 0.08050873 0.        ]]\n",
      "\tsimilarity of document 1 with others\n",
      "[[0.60757112 1.         0.         0.05344989 0.24218134 0.15218121\n",
      "  0.37476685 0.         0.         0.        ]]\n",
      "\tsimilarity of document 2 with others\n",
      "[[0.14815826 0.         1.         0.         0.         0.63703693\n",
      "  0.1403831  0.62378087 0.10583835 0.        ]]\n",
      "\tsimilarity of document 3 with others\n",
      "[[0.06301636 0.05344989 0.         1.         0.50206075 0.03985504\n",
      "  0.02985467 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity = TextSimilarity()\n",
    "similarity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
